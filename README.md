# LLM Benchmark

## Get started 
TBD

## Results

Find some videos of example prompts [here](https://app.clickup.com/t/86c32ythz) to see how responsive model are.

## Macmini
specs: 14CPU's (ARM64) 20GPU's, 64G memory
| Model Name | # of Eval Rates | Average Eval Rate (tokens/s) |
|------------|------------------|-------------------------------|
| deepseek-r1:1.5b | 5 | 122.44 |
| gemma3:1b | 5 | 143.38 |
| gemma3:4b | 5 | 65.25 |
| deepseek-r1:7b | 5 | 42.68 |

## aws-t2-med
specs: 2 vCPU's (i386), 4G memory

| Model Name | # of Eval Rates | Average Eval Rate (tokens/s) |
|------------|------------------|-------------------------------|
| deepseek-r1:1.5b | 5 | 9.71 |
| gemma3:1b | 5 | 11.02 |
